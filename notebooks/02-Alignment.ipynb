{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alignment & Operatrions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alignment\n",
    "\n",
    "- Working with multiple pandas objects\n",
    "- Structuring your data to make analysis easier\n",
    "- Using labels to their full potential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is more about *understanding* pandas, \"going with the flow\", than any particular method or operation.\n",
    "Alignment is a key part of many parts of pandas, including\n",
    "\n",
    "- binary operations (`+, -, *, /, **, ==, |, &`) between pandas objects\n",
    "- merges / joins / concats\n",
    "- constructors (`pd.DataFrame`, `pd.Series`)\n",
    "- reindexing\n",
    "\n",
    "That said, it's not really something you'll be doing explicitly.\n",
    "It happens in the background, as part of all those tasks.\n",
    "It's all about pandas using *labels* (`Seies/DataFrame.index` and `DataFrame.columns`) to do the tricky work of making sure the operation goes through correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 10\n",
    "sns.set(context='talk')\n",
    "plt.style.use('default')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alignment without row labels (bad)\n",
    "\n",
    "- separate datasets on GDP and CPI\n",
    "- Goal: compute real GDP\n",
    "- Problem: Different frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I grabbed some data from [FRED](https://fred.stlouisfed.org/) on nominal US GDP (total output each quarter) and CPI (a measure of inflation).\n",
    "Each CSV has a column of dates, and a column for the measurement.\n",
    "\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th>DATE</th>\n",
    "      <th>CPIAUCSL</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td>1947-01-01</td>\n",
    "      <td>21.48</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>1947-02-01</td>\n",
    "      <td>21.62</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>1947-03-01</td>\n",
    "      <td>22.00</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>1947-04-01</td>\n",
    "      <td>22.00</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>1947-05-01</td>\n",
    "      <td>21.95</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typically, we would use `DATE` as the index (`index_col='DATE'` in `read_csv`).\n",
    "But to appreciate the value of labels, we'll take them away for now.\n",
    "This will result in the default `range(n)` index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The \"wrong\" way\n",
    "# Read in CPI & GDP, parsing the dates\n",
    "gdp_bad = pd.read_csv(\"data/gdp.csv\", parse_dates=['DATE'])\n",
    "cpi_bad = pd.read_csv(\"data/cpi.csv\", parse_dates=['DATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp_bad.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpi_bad.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal: Compute Real GDP\n",
    "\n",
    "- nomial GDP: Total output in dollars\n",
    "- real GDP: Total output in constant dollars\n",
    "- $\\mathrm{real\\ gdp} = \\frac{\\mathrm{nomial\\ gdp}}{\\mathrm{inflation}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our task is to calculate *real* GDP.\n",
    "The data in the CSV is nominal GDP; it hasn't been adjusted for inflation.\n",
    "To compute real GDP, you take nomial GDP (`gdp_bad`) and divide by a measure of inflation (`cpi_bad`).\n",
    "\n",
    "Ideally, this would be as simple as `gdp_bad / cpi_bad`, but we have a slight issue: `gdp_bad` is measured quarterly, while `cpi_bad` is monthly.\n",
    "The two need to be *aligned* before we can do the conversion from nominal to real GDP.\n",
    "\n",
    "Normally, pandas would do this for us, but since we don't have meaningful row labels we have to do it manually.\n",
    "We'll find the dates in common between the two series, manually filter to those, and then do the division.\n",
    "You could do this a few ways; we'll go with a sql-style merge, roughly:\n",
    "\n",
    "```SQL\n",
    "select \"DATE\",\n",
    "       GDP / CPIAUCSL as real_gdp\n",
    "  from gdp_data\n",
    "  join cpi_data using (\"DATE\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge on DATE, divide\n",
    "m = pd.merge(gdp_bad, cpi_bad, on='DATE', how='inner')\n",
    "m.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m['GDP'] / m['CPIAUCSL']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problems\n",
    "\n",
    "1. The output has lost the `DATE` fields, we would need to manually bring those along after doing the division\n",
    "2. We had to worry about doing the merge, which is incidental to the problem of calculating real gdp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Better Way\n",
    "\n",
    "- Use row labels\n",
    "- Specify `index_col='DATE'` in `read_csv`\n",
    "- Just do the operation: `gdp / cpi`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we have meaningful row labels shared across pandas objects, pandas will handle all the fiddly details for alignment for us.\n",
    "Let's do things the proper way now, using `DATE` as our row labels.\n",
    "\n",
    "We could use `gdp = gdp_bad.set_index(\"DATE\")` to move a column into the index, but we'll just re-read the data from disk using the `index_col` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use .squeeze to convert a 1 column df to a Series\n",
    "gdp = pd.read_csv('data/gdp.csv', index_col='DATE',\n",
    "                  parse_dates=['DATE']).squeeze()\n",
    "gdp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpi = pd.read_csv('data/cpi.csv', index_col='DATE',\n",
    "                  parse_dates=['DATE']).squeeze()\n",
    "cpi.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now when you do the division, pandas will handle the alignemnt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgdp = gdp / cpi\n",
    "rgdp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll notice that a bunch of the values are `NaN`, short for [\"Not A Number\"](https://en.wikipedia.org/wiki/NaN).\n",
    "This is the missing value indicator pandas uses for numeric data.\n",
    "The `NaN`s are there because alignment produces the *union* of the two Indexes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explicit Alignment\n",
    "\n",
    "Roughly speaking, alignment composes two operations:\n",
    "\n",
    "1. union the labels\n",
    "2. reindex the data to conform to the unioned labels, inserting `NaN`s where necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1: union indexes\n",
    "\n",
    "full_idx = gdp.index | cpi.index  # | is set union on Index\n",
    "full_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# step 2: reindex\n",
    "gdp.reindex(full_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the data have been reindexed, the operation (like `/` in our case) proceedes.\n",
    "\n",
    "Ocassionally, you will do a manual `reindex`, but most of the time it's done in the background when you do an operation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" data-title=\"Compute Real GDP\">\n",
    "  <h1><i class=\"fa fa-tasks\" aria-hidden=\"true\"></i> Exercise: Compute Real GDP</h1>\n",
    "</div>\n",
    "\n",
    "<p>Compute real GDP in 2009 dollars</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll hear real GDP reported in '2009 dollars', or '2005 dollars'.\n",
    "The deflator (CPI in our case) is an index, and doesn't really have units.\n",
    "Some time span is chosen to be the base and set equal to 100.\n",
    "Every other observation is relative to it.\n",
    "The [data from FRED](https://fred.stlouisfed.org/series/CPIAUCSL) is indexed to 1982-1984.\n",
    "\n",
    "For the exercise, compute real-gdp in 2009 dollars.\n",
    "\n",
    "- Step 1: Convert CPI from base 1982-1984, to base 2009; Create a new series `cpi09` where the average value for 2009 is 100\n",
    "    + Hint: Use [partial string indexing](http://pandas.pydata.org/pandas-docs/stable/timeseries.html#datetimeindex-partial-string-indexing) to slice the values for just 2009\n",
    "    + Divide the original `cpi` by that value and rescale to be an index (1 -> 100)\n",
    "- Step 2: Divide `gdp` by the result from Step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load solutions/alignment_real_gdp09.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To the extent possible, you should use *meaningful labels*, rather than the default `range(n)` index.\n",
    "This will put the burden of aligning things on pandas, rather than your memory.\n",
    "Additionally, labels like the date are often \"nuisance\" columns, that would have to be dropped and recombined when doing arithmetic calculations.\n",
    "When they're in the `.index`, they come along with the calculation but don't get in the way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alignment on *both* axis\n",
    "\n",
    "This may surpise you at some point down the road."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we used the `.squeeze()` method to turn the 1-D `DataFrame` down to a `Series`.\n",
    "We did this, because pandas will align on both the index *and* columns.\n",
    "Can you guess what would happen if we divided two DataFrames, with different column names?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp_ = pd.read_csv('data/gdp.csv', index_col='DATE',\n",
    "                   parse_dates=['DATE'])\n",
    "gdp_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpi_ = pd.read_csv('data/cpi.csv', index_col='DATE',\n",
    "                   parse_dates=['DATE'])\n",
    "cpi_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp_ / cpi_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So pandas aligned by the columns, in addition to the index.\n",
    "Recall that alignment does the set *union*, so the output DataFrame has both CPI and GDP, which probably isn't what we wanted here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aside: Handling Missing Data\n",
    "\n",
    "Pandas, recognizing that missing data is a fact of life, has a bunch of methods for detecting and handling missing data.\n",
    "\n",
    "1. detecting missing data\n",
    "2. dropping missing data\n",
    "3. filling missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detecting Missing Data\n",
    "\n",
    "1. `pd.isna(), df.isna()`\n",
    "2. `pd.notna(), df.notana()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect with `isna` and `notna`\n",
    "\n",
    "rgdp.isna().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgdp.notna().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are often useful as masks for boolean indexing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgdp[rgdp.isna()].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or for counting (True counts as 1, and False as 0 for numeric operations):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgdp.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping Missing Data\n",
    "\n",
    "You can drop missing values with `.dropna`\n",
    "\n",
    "```\n",
    "DataFrame.dropna\n",
    "\n",
    "Return object with labels on given axis omitted where\n",
    "alternately any or all of the data are missing\n",
    "\n",
    "Parameters\n",
    "----------\n",
    "axis : {0 or 'index', 1 or 'columns'}, or tuple/list thereof\n",
    "    Pass tuple or list to drop on multiple axes\n",
    "how : {'any', 'all'}\n",
    "    * any : if any NA values are present, drop that label\n",
    "    * all : if all values are NA, drop that label\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgdp.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almost all pandas methods return a new Series or DataFrame, and do not mutate data inplace.\n",
    "`rgdp` still has the missing vaules, even though we called `.dropna`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgdp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make the change stick, you can assign the output to a new variable (or re-assign it to `rgdp`) like `rgdp = rgdp.dropna()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropna for DataFrames\n",
    "\n",
    "Since `DataFrame` is a 2-d container, there are additional complexities with dropping missing data.\n",
    "Do you drop the row or column? Does just one value in the row or column have to be missing, or all of them?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll see concat later\n",
    "df = pd.concat([gdp, cpi], axis='columns')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The defaults, shown next, are to drop *rows* (`axis='index'`) that\n",
    "have at any missing values (`how='any'`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(axis='index', how='any')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can drop a row only if all of it's values are missing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(axis='index', how='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" data-title=\"Dropping Columns\">\n",
    "  <h1><i class=\"fa fa-tasks\" aria-hidden=\"true\"></i> Exercise: Dropping Columns</h1>\n",
    "</div>\n",
    "<p>Drop any `columns` in `df` that have at least one missing value</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load solutions/dropna_columns.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filling Missing Values\n",
    "\n",
    "Use `.fillna` to fill with a value (scalar, or mapping of `label: value`) or method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's also `.fillna` to fill missing values, either with a value (which can be a scalar or array) or a method like `ffill` to fill-foward the last-observed value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgdp.fillna(method='ffill').plot()\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing data will come up throughout."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joining Pandas Objects\n",
    "\n",
    "You have some options:\n",
    "\n",
    "1. `pd.merge`: SQL-style joins\n",
    "2. `pd.concat`: array-style joins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll run into problems where you have multiple `Series` or `DataFrame`s, that you want to join into a single `DataFrame`.\n",
    "We saw an example of this earlier, but let's follow it up as a pair of exercises.\n",
    "\n",
    "There are two main ways to do this, `pd.merge` and `pd.concat`.\n",
    "\n",
    "When to use `merge` vs. `concat`?\n",
    "My general rule is to use `concat` for one-to-one joins of two or more Series/DataFrames, where your joining on the index.\n",
    "I use `pd.merge` when doing database style joins that are one-to-many, or many-to-many, or whenever you're joining on a column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" data-title=\"Merge Datasets\">\n",
    "  <h1><i class=\"fa fa-tasks\" aria-hidden=\"true\"></i> Exercise: Merge Datasets</h1>\n",
    "</div>\n",
    "\n",
    "<p>\n",
    "Use [`pd.merge`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.merge.html) to join the two DataFrames `gdp_bad` and `cpi_bad`, using an *outer* join (earlier we used an *inner* join).\n",
    "</p>\n",
    "\n",
    "- Hint: You may want to sort by date afterward (see [`DataFrame.sort_values`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.sort_values.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load solutions/aligment_merge.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" data-title=\"Concatenate Datasets\">\n",
    "  <h1><i class=\"fa fa-tasks\" aria-hidden=\"true\"></i> Exercise: Concatenate Datasets</h1>\n",
    "</div>\n",
    "\n",
    "<p>\n",
    "Use [`pd.concat`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.concat.html) to stick together `gdp` and `cpi` into a DataFrame</p>\n",
    "\n",
    "- Hint: what should the argument to `axis` be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load solutions/aligment_concat.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ufuncs And Reductions\n",
    "\n",
    "These next couple of topics aren't really related to alignment, but I didn't have anywhere else to put them.\n",
    "\n",
    "NumPy has the concept of [universal functions](https://docs.scipy.org/doc/numpy/reference/ufuncs.html) (ufuncs) that operate on any sized array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ufuncs` work elementwise, which means they don't care about the dimensions, just the data types.\n",
    "Even something like adding a scalar is a ufunc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df + 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reductions\n",
    "\n",
    "`DataFrame` has many methods that *reduce* a DataFrame to a Series by aggregating over a dimension.\n",
    "Likewise, `Series` has many methods that collapse down to a scalar.\n",
    "Some examples are `.mean`, `.std`, `.max`, `.any`, `.all`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get a DataFrame with two columns on a similar scale.\n",
    "The `pct_change` method returns the `(current - previous) / previous` for each row (with `NaN` for the first since there isn't a previous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pct_change = df.dropna().pct_change()\n",
    "pct_change.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pct_change.plot();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, the index (0) axis is reduced for `DataFrames`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pct_change.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To collapse the columns (leaving the same row labels), use the `axis` argument.\n",
    "Specifying `axis='columns'` or `axis=1` will aggregate over the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pct_change.max(axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have trouble remembering, the `axis` argument specifies the axis you want to *remove*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which column had the larger percent change?\n",
    "pct_change.idxmax(axis=\"columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" data-title=\"Percent Positive\">\n",
    "  <h1><i class=\"fa fa-tasks\" aria-hidden=\"true\"></i> Exercise: Percent Positive</h1>\n",
    "</div>\n",
    "\n",
    "\n",
    "<p>Exercise: What percent of the periods had a positive percent change for each column?</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load solutions/alignment_positive.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" data-title=\"JOLTS\">\n",
    "  <h1><i class=\"fa fa-tasks\" aria-hidden=\"true\"></i> Exercise: JOLTS</h1>\n",
    "</div>\n",
    "\n",
    "<p>\n",
    "(This is an optional exercise, if you're working ahead).\n",
    "\n",
    "During the housing bubble and financial crisis, [CalculatedRisk](http://www.calculatedriskblog.com) was one of the best places for information on the internet. Let's reproduce one of his charts:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display.Image(url='http://1.bp.blogspot.com/-Q60opady2iQ/VNoeGepLMWI/AAAAAAAAiQc/PCA1LfFJFCg/s1600/JOLTSDec2014.PNG')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows the components of turnover in the labor market. People leave jobs for two reasons:\n",
    "\n",
    "1. Quits (light blue) or\n",
    "2. Layoffs, discharges, or other (red).\n",
    "\n",
    "Companies post job openings (yellow) and fill some number of those (Blue).\n",
    "The difference between the openings and hires represents the change in the stock of open positions, and measures the slackness of the labor market.\n",
    "The difference between the Hires and the sum of Quites and Layoffs / Discharges represents the change in the employed labor force (though the unemployment rate is calculated differently).\n",
    "\n",
    "To get you started, the FRED series codes are\n",
    "\n",
    "- JTSJOL: Openings\n",
    "- JTSQUL: Quits\n",
    "- JTSHIL: Hires\n",
    "- JTSLDL: Layoffs\n",
    "\n",
    "Use the `pandas_datareader.data.DataReader` class, which accepts a list of symbols, and a data_source (`'fred'`).\n",
    "As a hint, you can use pandas' `.plot.area()` method for the Quits and Layoffs series. That handles all the stacking for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas.core is private\n",
    "# don't do this at home\n",
    "pd.core.common.is_list_like = pd.core.dtypes.inference.is_list_like\n",
    "\n",
    "from pandas_datareader.data import DataReader\n",
    "\n",
    "series = ['JTSJOL', 'JTSQUL', 'JTSHIL', 'JTSLDL']\n",
    "names = ['openings', 'quits', 'hires', 'layoffs']\n",
    "\n",
    "colors = {'quits': '#52b5ea', 'layoffs': '#d32c2c',\n",
    "          'hires': '#2531db', 'openings': '#fffb49'}\n",
    "\n",
    "area_colors = [colors['quits'], colors['layoffs']]\n",
    "line_colors = [colors['hires'], colors['openings']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load solutions/alignment_03.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you finish that, feel free to poke around [FRED](https://fred.stlouisfed.org) for more interesting series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "- Auto-alignment in pandas is different than most other systems\n",
    "- Let pandas handle the details of alignment, you worry about important things\n",
    "- Pandas methods are non-mutating\n",
    "- `.dropna`, `.filla`, `isnull` for handling missing data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
